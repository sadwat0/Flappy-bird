{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.2.0 (SDL 2.0.22, Python 3.10.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "couldn't import doomish\n",
      "Couldn't import doom\n"
     ]
    }
   ],
   "source": [
    "from ple import PLE\n",
    "import numpy as np\n",
    "from ple.games.flappybird import FlappyBird\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state(s):\n",
    "    dx = int(s['next_pipe_dist_to_player'])\n",
    "    dy = int(s['player_y'] - s['next_pipe_bottom_y'])\n",
    "    vel = int(s['player_vel'])\n",
    "\n",
    "    rx = 20\n",
    "    ry = 10\n",
    "    dx = rx * (dx // rx)\n",
    "    dy = ry * (dy // ry)\n",
    "\n",
    "    res = str(dx) + '_' + str(dy) + '_' + str(vel)\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = [-1000, 0.1]\n",
    "# die, nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, size):\n",
    "        self._storage = []\n",
    "        self._maxsize = size\n",
    "        self._replaceId = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._storage)\n",
    "\n",
    "    def add(self, obs_t, action, reward, obs_tp1):\n",
    "        data = (obs_t, action, reward, obs_tp1)\n",
    "        if len(self._storage) == self._maxsize:\n",
    "            self._storage[self._replaceId] = data\n",
    "            self._replaceId = (self._replaceId + 1) % self._maxsize\n",
    "        else:\n",
    "            self._storage.append(data)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        next_states = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            data = random.choice(self._storage)\n",
    "            state, action, reward, next_state = data\n",
    "\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            next_states.append(next_state)\n",
    "        \n",
    "        return states, actions, rewards, next_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent():\n",
    "  def __init__(self, alpha, epsilon, discount, need_train, load_from=None, save_to=None):\n",
    "    self.is_training = need_train\n",
    "    self.load_from = load_from\n",
    "    self.save_to = save_to\n",
    "\n",
    "    self.qValues = {}\n",
    "    self.alpha = alpha\n",
    "    self.epsilon = epsilon\n",
    "    self.discount = discount\n",
    "\n",
    "    self.moves = []\n",
    "    # self.replay = ReplayBuffer(10000)\n",
    "    self.played = 0\n",
    "\n",
    "    self.best_score = -1\n",
    "    self.records = []\n",
    "    self.mean_rewards = []\n",
    "\n",
    "    self.load_qvalues()\n",
    "\n",
    "  def get_qValue(self, state, action):\n",
    "    if not (state in self.qValues):\n",
    "      self.qValues[state] = [0, 0, 0] # do nothing, flap, had_before\n",
    "      return 0.0\n",
    "\n",
    "    return self.qValues[state][action]\n",
    "\n",
    "  def set_qValue(self, state, action, value):\n",
    "    self.qValues[state][action] = value\n",
    "\n",
    "# -----------\n",
    "\n",
    "  def get_action(self, state):\n",
    "    # 0 - do nothing\n",
    "    # 1 - flap\n",
    "\n",
    "    s = convert_state(state)\n",
    "\n",
    "    if random.random() < self.epsilon or self.get_qValue(s, 2) == 0:\n",
    "      return random.random() >= 0.9 \n",
    "\n",
    "    return self.get_qValue(s, 1) > self.get_qValue(s, 0)\n",
    "  \n",
    "  def episode_end(self):\n",
    "    self.epsilon = max(0.01, self.epsilon * 0.9993)\n",
    "    # self.alpha = max(0.05, self.alpha - self.alpha_decay)\n",
    "\n",
    "    if self.is_training:\n",
    "      moves = list(reversed(self.moves))\n",
    "\n",
    "      time_from_die = 0\n",
    "      for (past_state, action, next_state) in moves:\n",
    "        reward = rewards[1]\n",
    "        \n",
    "        time_from_die += 1\n",
    "        \n",
    "        if time_from_die <= 4:\n",
    "          reward = rewards[0]\n",
    "\n",
    "        past_s = convert_state(past_state)\n",
    "        next_s = convert_state(next_state)\n",
    "\n",
    "        learning_rate = self.alpha\n",
    "        self.set_qValue(past_s, action, (1 - learning_rate) * self.get_qValue(past_s, action) + \\\n",
    "                        learning_rate * (reward + self.discount * max(self.get_qValue(next_s, 0), self.get_qValue(next_s, 1))))\n",
    "\n",
    "        # self.replay.add(past_s, action, reward, next_s)\n",
    "        self.set_qValue(past_s, 2, self.get_qValue(past_s, 2) + 1)\n",
    "    \n",
    "    self.moves = []\n",
    "\n",
    "  def update(self, batch_size=10):\n",
    "    if self.replay.__len__() == 0:\n",
    "      return\n",
    "    \n",
    "    states, actions, rewards, next_states = self.replay.sample(batch_size)\n",
    "    for i in range(len(states)):\n",
    "      gamma = self.discount\n",
    "      learning_rate = self.alpha\n",
    "      self.set_qValue(states[i], actions[i], (1 - learning_rate) * self.get_qValue(states[i], actions[i]) + \\\n",
    "                        learning_rate * (rewards[i] + gamma * max(self.get_qValue(next_states[i], 0), self.get_qValue(next_states[i], 1))))\n",
    "\n",
    "  def add_move(self, past_state, action, next_state):\n",
    "    self.moves.append((past_state, action, next_state))\n",
    "\n",
    "  def load_qvalues(self):\n",
    "    if (self.load_from == None):\n",
    "      return\n",
    "    \n",
    "    print(f\"Loading saved Q-table states from {self.load_from}...\")\n",
    "    try:\n",
    "      with open(self.load_from, \"r\") as f:\n",
    "        saves = json.load(f)\n",
    "        self.played = saves['played']\n",
    "        self.epsilon = saves['epsilon']\n",
    "        self.qValues = saves['qValues']\n",
    "        self.mean_rewards = saves['mean_rewards']\n",
    "        self.best_score = saves['best_score']\n",
    "        self.records = saves['records']\n",
    "        print(\"Loaded successfully!\")\n",
    "    except IOError:\n",
    "      print(\"No saves found\")\n",
    "\n",
    "  def save_qvalues(self):\n",
    "    if self.save_to != None:\n",
    "      print(f\"Saving Q-table with {len(self.qValues.keys())} states to file...\")\n",
    "      with open(self.save_to, \"w\") as f:\n",
    "        json_data = {\n",
    "          'played': self.played,\n",
    "          'epsilon': self.epsilon,\n",
    "          'qValues': self.qValues,\n",
    "          'mean_rewards': self.mean_rewards,\n",
    "          'best_score': self.best_score,\n",
    "          'records': self.records,\n",
    "        }\n",
    "\n",
    "        json.dump(json_data, f, sort_keys=True, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = FlappyBird()\n",
    "\n",
    "p = PLE(game, fps=30, display_screen=False, force_fps=True)\n",
    "p.init()\n",
    "\n",
    "possible_actions = p.getActionSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def play_and_train(agent, play_time = 15, save_qvalues = False):\n",
    "    time_end = time.time() + 60 * play_time\n",
    "    agent.mean_rewards = []\n",
    "\n",
    "    # we will plot graph with mean score of past k games\n",
    "    k = 1\n",
    "    past_k_results = []\n",
    "\n",
    "    past_mx = 0.0\n",
    "    current_score = 0.0\n",
    "    played_games = 0\n",
    "\n",
    "    while time.time() < time_end:\n",
    "        if p.game_over():\n",
    "            p.reset_game()\n",
    "            played_games += 1\n",
    "\n",
    "            agent.episode_end()\n",
    "            agent.played += 1\n",
    "\n",
    "            if (current_score > agent.best_score):\n",
    "                agent.best_score = current_score\n",
    "                agent.records.append((current_score, agent.played))\n",
    "            \n",
    "            past_k_results.append(current_score)\n",
    "            if len(past_k_results) == k:\n",
    "                agent.mean_rewards.append(np.mean(past_k_results))\n",
    "                past_k_results = []\n",
    "\n",
    "            past_mx = max(past_mx, current_score)\n",
    "\n",
    "            # remove \"or True\" part if plot reloads often\n",
    "            if agent.played % 100 == 0 or True:\n",
    "                clear_output(True)\n",
    "                print(f\"N: {agent.played}, best: {agent.best_score}, past {k}: {past_mx}, eps: {agent.epsilon}\")\n",
    "                \n",
    "                # plt.plot(range(1, len(rewards) + 1), rewards, label=\"reward\")\n",
    "                plt.plot(np.linspace(1, len(rewards), num=len(agent.mean_rewards)), agent.mean_rewards, label=\"mean reward\")\n",
    "                plt.xlabel(\"game\")\n",
    "                plt.ylabel(\"score\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "                past_mx = 0.0\n",
    "\n",
    "            current_score = 0.0\n",
    "\n",
    "        state = p.getGameState()\n",
    "        action = agent.get_action(state)\n",
    "\n",
    "        score_change = p.act(possible_actions[action ^ 1])\n",
    "        current_score += score_change > 0\n",
    "\n",
    "        next_state = p.getGameState()\n",
    "        agent.add_move(state, action, next_state)\n",
    "\n",
    "        # agent.update(batch_size=3)\n",
    "    \n",
    "    if save_qvalues:\n",
    "        agent.save_qvalues()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    agent = QLearningAgent(alpha=0.2, epsilon=1, discount=0.97, need_train=1, load_from=\"data/q_values.json\", save_to=None)\n",
    "    play_and_train(agent=agent, play_time=15, save_qvalues=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
